services:
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - MODELS_DIR=/app/data/models
      - UPLOADS_DIR=/app/data/uploads
      - DEBUG=false
      - DEFAULT_MODEL=qari
    volumes:
      - ./data/models:/app/data/models
      - ./data/uploads:/app/data/uploads
    depends_on:
      - redis
    restart: unless-stopped

  worker:
    build: .
    command: rq worker --url redis://redis:6379/0
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - MODELS_DIR=/app/data/models
      - UPLOADS_DIR=/app/data/uploads
      - DEFAULT_MODEL=qari
      - HF_HUB_ENABLE_HF_TRANSFER=0
      - HF_HUB_DISABLE_TELEMETRY=1
      - HF_HUB_DISABLE_INTERACTIVE=1
      - TRANSFORMERS_OFFLINE=0
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
    volumes:
      - ./data/models:/app/data/models
      - ./data/uploads:/app/data/uploads
      - huggingface-cache:/root/.cache/huggingface
    depends_on:
      - redis
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped

volumes:
  redis_data:
  huggingface-cache:
